{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was agreed that we need to select the strongest three out of ten available features. Preferably, these should be a1, b1 and c1 (see dataset-generation.ipynb). a2, b2, c2, c3 may also appear as substitutes of those three, but it is not much welcomed. d1, d2 or d3 should not be selected as they are just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init( '/usr/local/spark' )\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import VectorAssembler, ChiSqSelector\n",
    "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "Myspark = SparkSession.builder.master( 'local' ).appName( 'Features' ).getOrCreate()\n",
    "print( Myspark.version )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Myspark.read.csv( '~/Documents/GitHub/feature-selection-spark/data.csv', \n",
    "                        inferSchema=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', 'double'),\n",
       " ('a1', 'int'),\n",
       " ('a2', 'double'),\n",
       " ('b1', 'int'),\n",
       " ('b2', 'double'),\n",
       " ('c1', 'double'),\n",
       " ('c2', 'double'),\n",
       " ('c3', 'double'),\n",
       " ('d1', 'double'),\n",
       " ('d2', 'double'),\n",
       " ('d3', 'double')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------\n",
      " label | 0.05505462852698298  \n",
      " a1    | 1                    \n",
      " a2    | 1.45847822002572     \n",
      " b1    | 0                    \n",
      " b2    | -1.529300753353182   \n",
      " c1    | -0.17780551487679785 \n",
      " c2    | 4.341582850035831    \n",
      " c3    | -1.0191714284369406  \n",
      " d1    | 0.13589342212035893  \n",
      " d2    | 2.0050211070711055   \n",
      " d3    | 1.4536196801663166   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA.show( 1, vertical=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = DATA.columns[ 1: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectFeatures( dataframe, feature_names, trials, groups=12 ) :\n",
    "    \"\"\" Selects most important uncorrelated features from a high-dimensional dataset. Based on trying diverse\n",
    "        decision trees in order to uncover hidden relationships.\n",
    "            dataframe: a Spark dataframe\n",
    "            feature_names: a list of all feature names considered for modeling\n",
    "            trials: number of different trees to try (the more, the better; depends on the computation capacity)\n",
    "            groups: indicator of detalisation of each tree (roughly speaking, it is a number of groupes the total\n",
    "                    sample is devided into; so larger values mean a higher detalisation and a larger number of\n",
    "                    selected features)\n",
    "        Note:\n",
    "        It is hard to estimate the number of selected features in advance. Several values for groups= should be\n",
    "            tried on small trials= (10-30) to understand what value provides approximately the desired number\n",
    "            of features.\n",
    "        Returns a dictionary where the keys are performance metric values and the values are arrays of relevant\n",
    "        column indices \"\"\"\n",
    "    vector = VectorAssembler( inputCols=feature_names, outputCol='features' )\n",
    "    evaluator = RegressionEvaluator( metricName='mae' )\n",
    "    np.random.seed( 333 )\n",
    "    seeds = np.random.randint( 0, 4e9, size=trials )\n",
    "    leaf = round( dataframe.count() / groups )\n",
    "    summary = {}\n",
    "    for oneseed in seeds :\n",
    "        tree = RandomForestRegressor( numTrees=1, minInstancesPerNode=leaf, maxDepth=30, maxBins=999, \n",
    "                                     subsamplingRate=0.5, featureSubsetStrategy='onethird', seed=oneseed )\n",
    "        pipe = Pipeline( stages=[ vector, tree ] )\n",
    "        model = pipe.fit( dataframe )\n",
    "        metricvalue = evaluator.evaluate( model.transform( dataframe ) )\n",
    "        summary[ metricvalue ] = model.stages[ 1 ].featureImportances.indices\n",
    "        del( [ tree, pipe, model, metricvalue ] )\n",
    "    summary = sorted( summary.items() )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features = SelectFeatures( DATA, names, trials=5000, groups=13 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing the best 4 feature sets (by MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4750700437352839, array([0, 2], dtype=int32))\n",
      "(0.592239726070981, array([0, 2, 4], dtype=int32))\n",
      "(0.5924034269231778, array([0, 2, 4], dtype=int32))\n",
      "(0.6055078534263866, array([0, 2, 5, 6], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "for i in [ 0, 1, 2, 3 ] :\n",
    "    print( possible_features[ i ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'b1', 'c1']\n"
     ]
    }
   ],
   "source": [
    "selected = [ names[ i ] for i in possible_features[ 1 ][ 1 ] ]\n",
    "print( selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little tuning of the \"groups\" parameter, the function returns the desired variables in the second- and third-best sets at 5000 trials (the first set contains too few variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with a regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1']\n"
     ]
    }
   ],
   "source": [
    "leaf = round( DATA.count() / 12 )\n",
    "vector = VectorAssembler( inputCols=names, outputCol='features' )\n",
    "evaluator = RegressionEvaluator( metricName='mae' )\n",
    "regtree = DecisionTreeRegressor( minInstancesPerNode=leaf, maxDepth=30, maxBins=999 )\n",
    "pipe = Pipeline( stages=[ vector, regtree ] )\n",
    "model = pipe.fit( DATA )\n",
    "regtree_selected = [ names[ i ] for i in model.stages[ 1 ].featureImportances.indices ]\n",
    "print( regtree_selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular decision tree selects only the weak linear variable. It is unable to detect the important variables a1 and b1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with a lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 0.0, 0.0, 0.2939, 0.0, 0.002, 0.0, 0.0061, 0.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasreg = LinearRegression( maxIter=100, regParam=0.01, elasticNetParam=1.0 )\n",
    "pipe = Pipeline( stages=[ vector, lasreg ] )\n",
    "model = pipe.fit( DATA )\n",
    "model.stages[ 1 ].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1', 'c3', 'd2']\n"
     ]
    }
   ],
   "source": [
    "print( [ names[ i ] for i, item in enumerate( model.stages[ 1 ].coefficients ) if item != 0 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lasso regression (with the regularization adjusted to return 3 coefficients) selects only the linear variables plus one garbage variable. So it also fails to detect the most important relationship between a1 and b1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with the ChiSqSelector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the target into a binary variable\n",
    "DATA = DATA.withColumn( 'label', when( DATA.label >= 0, 1 ).otherwise( 0 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d3', 'd1', 'c1']\n"
     ]
    }
   ],
   "source": [
    "chisq = ChiSqSelector( numTopFeatures=3 )\n",
    "pipe = Pipeline( stages=[ vector, chisq ] )\n",
    "model = pipe.fit( DATA )\n",
    "chisq_selected = [ names[ i ] for i in model.stages[ 1 ].selectedFeatures ]\n",
    "print( chisq_selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Squared feature selection chooses one linear and garbage variables which is, again, insufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myspark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is able to select a small set of the most important variables taking into account complex relationships across them. Other algorithms suitable for feature filtering fail to capture all kinds of relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
