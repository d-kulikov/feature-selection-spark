{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was agreed that we need to select the strongest three out of ten available features. Preferably, these should be a1, b1 and c1 (see dataset-generation.ipynb). a2, b2, c2, c3 may also appear as substitutes of those three, but it is not much welcomed. d1, d2 or d3 should not be selected as they are just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init( '/usr/local/spark' )\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "Myspark = SparkSession.builder.master( 'local' ).appName( 'Features' ).getOrCreate()\n",
    "print( Myspark.version )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Myspark.read.csv( '/home/demetrius/Documents/GitHub/feature-selection-spark/data.csv', \n",
    "                        inferSchema=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', 'double'),\n",
       " ('a1', 'int'),\n",
       " ('a2', 'double'),\n",
       " ('b1', 'int'),\n",
       " ('b2', 'double'),\n",
       " ('c1', 'double'),\n",
       " ('c2', 'double'),\n",
       " ('c3', 'double'),\n",
       " ('d1', 'double'),\n",
       " ('d2', 'double'),\n",
       " ('d3', 'double')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------\n",
      " label | 0.05505462852698298  \n",
      " a1    | 1                    \n",
      " a2    | 1.45847822002572     \n",
      " b1    | 0                    \n",
      " b2    | -1.529300753353182   \n",
      " c1    | 0.1574185974126949   \n",
      " c2    | 1.8302946297668106   \n",
      " c3    | -0.08012381649940253 \n",
      " d1    | -0.5668537223849737  \n",
      " d2    | 2.400231562805219    \n",
      " d3    | 3.2270143265957785   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA.show( 1, vertical=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = DATA.columns[ 1: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectFeatures( dataframe, feature_names, trials, groups=12 ) :\n",
    "    \"\"\" Selects most important uncorrelated features from a high-dimensional dataset. Based on trying diverse\n",
    "        decision trees in order to uncover hidden relationships.\n",
    "            dataframe: a Spark dataframe\n",
    "            feature_names: a list of all feature names considered for modeling\n",
    "            trials: number of different trees to try (the more, the better; depends on the computation capacity)\n",
    "            groups: indicator of detalisation of each tree (roughly speaking, it is a number of groupes the total\n",
    "                    sample is devided into; so larger values mean a higher detalisation and a larger number of\n",
    "                    selected features)\n",
    "        Note:\n",
    "        It is hard to estimate the number of selected features in advance. Several values for groups= should be\n",
    "            tried on small trials= (10-30) to understand what value provides approximately the desired number\n",
    "            of features.\n",
    "        Returns a dictionary where the keys are performance metric values and the values are arrays of relevant\n",
    "        column indices \"\"\"\n",
    "    vector = VectorAssembler( inputCols=feature_names, outputCol='features' )\n",
    "    input = vector.transform( DATA )\n",
    "    evaluator = RegressionEvaluator( metricName='mae' )\n",
    "    leaf = round( dataframe.count() / groups )\n",
    "    forest = RandomForestRegressor( numTrees=trials, minInstancesPerNode=leaf, maxDepth=30, maxBins=999, \n",
    "                                     subsamplingRate=0.5, featureSubsetStrategy='onethird', seed=333 )\n",
    "    model = forest.fit( input )\n",
    "    summary = {}\n",
    "    for i in range( trials ) :\n",
    "        print( i )\n",
    "        metricvalue = evaluator.evaluate( model.trees[ i ].transform( input ) )\n",
    "        summary[ metricvalue ] = model.trees[ i ].featureImportances.indices\n",
    "    summary = sorted( summary.items() )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "possible_features = SelectFeatures( DATA, names, trials=1000, groups=14 )\n",
    "print( time() - start )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing the best 3 feature sets (by MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.644477272060006, array([0, 1, 2, 6], dtype=int32))\n",
      "(0.7196706658336792, array([4], dtype=int32))\n",
      "(0.7202045800323651, array([3, 4], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "for i in [ 0, 1, 2 ] :\n",
    "    print( possible_features[ i ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b2', 'c1']\n"
     ]
    }
   ],
   "source": [
    "selected = [ names[ i ] for i in possible_features[ 2 ][ 1 ] ]\n",
    "print( selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with a little tuning of the 'groups' parameter (to restrict only 3 variables) the function returns the desired set of variables (see dataset-generation.ipynb) at 1000 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with a regular decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1', 'd1', 'd3']\n"
     ]
    }
   ],
   "source": [
    "leaf = round( DATA.count() / 12 )\n",
    "vector = VectorAssembler( inputCols=names, outputCol='features' )\n",
    "evaluator = RegressionEvaluator( metricName='mae' )\n",
    "regtree = DecisionTreeRegressor( minInstancesPerNode=leaf, maxDepth=30, maxBins=999 )\n",
    "pipe = Pipeline( stages=[ vector, regtree ] )\n",
    "model = pipe.fit( DATA )\n",
    "regtree_selected = [ names[ i ] for i in model.stages[ 1 ].featureImportances.indices ]\n",
    "print( regtree_selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular decision tree selects the weak linear variable and garbage variables. It is unable to detect the important relationship between a1, b1 and the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with a lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 0.0, 0.0, -0.0006, 0.1896, 0.0, 0.0, 0.0007, 0.0, 0.0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasreg = LinearRegression( maxIter=100, regParam=0.011, elasticNetParam=1.0 )\n",
    "pipe = Pipeline( stages=[ vector, lasreg ] )\n",
    "model = pipe.fit( DATA )\n",
    "model.stages[ 1 ].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b2', 'c1', 'd1']\n"
     ]
    }
   ],
   "source": [
    "print( [ names[ i ] for i, item in enumerate( model.stages[ 1 ].coefficients ) if item != 0 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lasso regression (with the regularization adjusted to return 3 coefficients) misses \"a\"-features, so it also fails to detect the most important relationship between a1 and b1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison with the ChiSqSelector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the target into a binary variable\n",
    "DATA = DATA.withColumn( 'label', when( DATA.label >= 0, 1 ).otherwise( 0 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq = ChiSqSelector( numTopFeatures=3 )\n",
    "pipe = Pipeline( stages=[ vector, chisq ] )\n",
    "model = pipe.fit( DATA )\n",
    "chisq_selected = [ names[ i ] for i in model.stages[ 1 ].selectedFeatures ]\n",
    "print( chisq_selected )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Squared feature selection chooses one linear and garbage variables which is, again, insufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Myspark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is able to select a small set of the most important variables taking into account complex relationships across them. Other algorithms suitable for feature filtering fail to capture all kinds of relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
